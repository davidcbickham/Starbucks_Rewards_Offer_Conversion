{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Learner Model - Hyperparameter Tuning Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import boto3\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker import image_uris\n",
    "from sagemaker.predictor import csv_serializer\n",
    "\n",
    "# This is an object that represents the SageMaker session that we are currently operating in. This\n",
    "# object contains some useful information that we will need to access later such as our region.\n",
    "session = sagemaker.Session()\n",
    "\n",
    "# This is an object that represents the IAM role that we are currently assigned. When we construct\n",
    "# and launch the training job later we will need to tell it what IAM role it should have. Since our\n",
    "# use case is relatively simple we will simply assign the training job the role we currently have.\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Library Documentation:\n",
    "- [Sagmaker Python SDK Documentation](https://sagemaker.readthedocs.io/en/stable/index.html)\n",
    "- [AWS Python SDK - Boto3 Documentation](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/quickstart.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Input Data Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is our local data directory. We need to make sure that it exists.\n",
    "data_dir = '../input'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "    \n",
    "# s3 bucket and prefix (folder in s3)\n",
    "bucket = session.default_bucket()\n",
    "prefix = 'mle-capstone'\n",
    "\n",
    "# location of datasets in s3\n",
    "train_location = f's3://{bucket}/{prefix}/train.csv'\n",
    "val_location = f's3://{bucket}/{prefix}/validation.csv'\n",
    "test_location = f's3://{bucket}/{prefix}/test.csv'\n",
    "Y_test_location = f's3://{bucket}/{prefix}/Y_test.csv'\n",
    "test_unprocessed_location = f's3://{bucket}/{prefix}/test_unprocessed.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and construct the Linear Learner model\n",
    "\n",
    "Now that we have the training and validation data uploaded to S3, we can construct a training job for our XGBoost model and build the model itself.\n",
    "\n",
    "### Set up the training job\n",
    "\n",
    "First, we will set up and execute a training job for our model. To do this we need to specify some information that SageMaker will use to set up and properly execute the computation. For additional documentation on constructing a training job, see the [CreateTrainingJob API](https://docs.aws.amazon.com/sagemaker/latest/dg/API_CreateTrainingJob.html) reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker.inputs.TrainingInput(s3_data=train_location,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"text/csv\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    "    record_wrapping=None,\n",
    "    compression=None\n",
    ")\n",
    "validation_data = sagemaker.inputs.TrainingInput(s3_data=val_location,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"text/csv\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    "    record_wrapping=None,\n",
    "    compression=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the training job\n",
    "\n",
    "Now that we've built the dictionary object containing the training job parameters, we can ask SageMaker to execute the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the linear learner image according to the region\n",
    "container = sagemaker.image_uris.retrieve(framework = \"linear-learner\"\n",
    "                                          , region = boto3.Session().region_name\n",
    "                                         , version=\"1\")\n",
    "training_job_name = \"starbucks-linear-learner-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "train_output_path = \"s3://\" + session.default_bucket() + \"/\" + prefix + \"/output\"\n",
    "\n",
    "linear = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    input_mode=\"File\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    output_path=train_output_path,\n",
    "    sagemaker_session=session,\n",
    ")\n",
    "\n",
    "linear.set_hyperparameters(\n",
    "    feature_dim= 14,\n",
    "    epochs= 16,\n",
    "    wd= 0.01,\n",
    "    loss= \"logistic\",\n",
    "    predictor_type= \"binary_classifier\",\n",
    "    normalize_data= True,\n",
    "    mini_batch_size= 100,\n",
    "    lr_scheduler_step= 100,\n",
    "    lr_scheduler_factor= 0.99,\n",
    "    lr_scheduler_minimum_lr= 0.0001,\n",
    "    learning_rate= 0.01,\n",
    "    binary_classifier_model_selection_criteria= \"f_beta\",\n",
    "    f_beta= 1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the Hyperparameter Tuning Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, CategoricalParameter, HyperparameterTuner\n",
    "\n",
    "linear_hyperparameter_tuner = HyperparameterTuner(estimator = linear, # The estimator object to use as the basis for the training jobs.\n",
    "                                               objective_metric_name = 'validation:binary_f_beta', # The metric used to compare trained models.\n",
    "                                               objective_type = 'Maximize', # Whether we wish to minimize or maximize the metric.\n",
    "                                               max_jobs = 20, # The total number of models to train\n",
    "                                               max_parallel_jobs = 3, # The number of models to train in parallel\n",
    "                                               strategy='Bayesian',\n",
    "                                               early_stopping_type='Auto',\n",
    "                                               hyperparameter_ranges = {\n",
    "                                                    'wd': ContinuousParameter(1e-7, 1.0),\n",
    "                                                    'l1': ContinuousParameter(1e-7, 1.0),\n",
    "                                                    'learning_rate': ContinuousParameter(1e-5, 1.0),\n",
    "                                                    'mini_batch_size': IntegerParameter(100, 500),\n",
    "                                                    'use_bias': CategoricalParameter([True, False]),\n",
    "                                                   'positive_example_weight_mult': ContinuousParameter(1e-5, 1e5)\n",
    "                                               })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Sagemaker HyperparameterTuner Documentation](https://sagemaker.readthedocs.io/en/stable/api/training/tuner.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Hyperparameter Tuning Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................................................................................................................................................................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "linear_hyperparameter_tuner.fit(inputs={\"train\": train_data, \"validation\": validation_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'linear-learner-210305-0556-020-3d7538db'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view details on the best training \n",
    "linear_hyperparameter_tuner.best_training_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HyperParameterTuningJobName': 'linear-learner-210305-0556',\n",
       " 'HyperParameterTuningJobArn': 'arn:aws:sagemaker:us-west-2:785913330910:hyper-parameter-tuning-job/linear-learner-210305-0556',\n",
       " 'HyperParameterTuningJobConfig': {'Strategy': 'Bayesian',\n",
       "  'HyperParameterTuningJobObjective': {'Type': 'Maximize',\n",
       "   'MetricName': 'validation:binary_f_beta'},\n",
       "  'ResourceLimits': {'MaxNumberOfTrainingJobs': 20,\n",
       "   'MaxParallelTrainingJobs': 3},\n",
       "  'ParameterRanges': {'IntegerParameterRanges': [{'Name': 'mini_batch_size',\n",
       "     'MinValue': '100',\n",
       "     'MaxValue': '500',\n",
       "     'ScalingType': 'Auto'}],\n",
       "   'ContinuousParameterRanges': [{'Name': 'wd',\n",
       "     'MinValue': '1e-07',\n",
       "     'MaxValue': '1.0',\n",
       "     'ScalingType': 'Auto'},\n",
       "    {'Name': 'l1',\n",
       "     'MinValue': '1e-07',\n",
       "     'MaxValue': '1.0',\n",
       "     'ScalingType': 'Auto'},\n",
       "    {'Name': 'learning_rate',\n",
       "     'MinValue': '1e-05',\n",
       "     'MaxValue': '1.0',\n",
       "     'ScalingType': 'Auto'},\n",
       "    {'Name': 'positive_example_weight_mult',\n",
       "     'MinValue': '1e-05',\n",
       "     'MaxValue': '100000.0',\n",
       "     'ScalingType': 'Auto'}],\n",
       "   'CategoricalParameterRanges': [{'Name': 'use_bias',\n",
       "     'Values': ['True', 'False']}]},\n",
       "  'TrainingJobEarlyStoppingType': 'Auto'},\n",
       " 'TrainingJobDefinition': {'StaticHyperParameters': {'_tuning_objective_metric': 'validation:binary_f_beta',\n",
       "   'binary_classifier_model_selection_criteria': 'f_beta',\n",
       "   'epochs': '16',\n",
       "   'f_beta': '1.0',\n",
       "   'feature_dim': '14',\n",
       "   'loss': 'logistic',\n",
       "   'lr_scheduler_factor': '0.99',\n",
       "   'lr_scheduler_minimum_lr': '0.0001',\n",
       "   'lr_scheduler_step': '100',\n",
       "   'normalize_data': 'True',\n",
       "   'predictor_type': 'binary_classifier'},\n",
       "  'AlgorithmSpecification': {'TrainingImage': '174872318107.dkr.ecr.us-west-2.amazonaws.com/linear-learner:1',\n",
       "   'TrainingInputMode': 'File',\n",
       "   'MetricDefinitions': [{'Name': 'test:dcg',\n",
       "     'Regex': '#quality_metric: host=\\\\S+, test dcg <score>=(\\\\S+)'},\n",
       "    {'Name': 'train:progress',\n",
       "     'Regex': '#progress_metric: host=\\\\S+, completed (\\\\S+) %'},\n",
       "    {'Name': 'test:binary_f_beta',\n",
       "     'Regex': '#quality_metric: host=\\\\S+, test binary_f_\\\\S+ <score>=(\\\\S+)'},\n",
       "    {'Name': 'train:objective_loss',\n",
       "     'Regex': '#quality_metric: host=\\\\S+, epoch=\\\\S+, train \\\\S+_objective <loss>=(\\\\S+)'},\n",
       "    {'Name': 'validation:macro_precision',\n",
       "     'Regex': '#quality_metric: host=\\\\S+, validation macro_precision <score>=(\\\\S+)'},\n",
       "    {'Name': 'validation:dcg',\n",
       "     'Regex': '#quality_metric: host=\\\\S+, validation dcg <score>=(\\\\S+)'},\n",
       "    {'Name': 'test:mse',\n",
       "     'Regex': '#quality_metric: host=\\\\S+, test mse <loss>=(\\\\S+)'},\n",
       "    {'Name': 'validation:binary_f_beta',\n",
       "     'Regex': '#quality_metric: host=\\\\S+, validation binary_f_\\\\S+ <score>=(\\\\S+)'},\n",
       "    {'Name': 'validation:objective_loss',\n",
       "     'Regex': '#quality_metric: host=\\\\S+, epoch=\\\\S+, validation \\\\S+_objective <loss>=(\\\\S+)'},\n",
       "    {'Name': 'validation:objective_loss:final',\n",
       "     'Regex': '#quality_metric: host=\\\\S+, validation \\\\S+_objective <loss>=(\\\\S+)'},\n",
       "    {'Name': 'test:macro_recall',\n",
       "     'Regex': '#quality_metric: host=\\\\S+, test macro_recall <score>=(\\\\S+)'},\n",
       "    {'Name': 'test:absolute_loss',\n",
       "     'Regex': '#quality_metric: host=\\\\S+, test absolute_loss <loss>=(\\\\S+)'},\n",
       "    {'Name': 'train:recall',\n",
       "     'Regex': '#quality_metric: host=\\\\S+, train recall <score>=(\\\\S+)'},\n",
       "    {'Name': 'train:mse',\n",
       "     'Regex': '#quality_metric: host=\\\\S+, train mse <loss>=(\\\\S+)'},\n",
       "    {'Name': 'validation:roc_auc_score',\n",
       "     'Regex': '#quality_metric: host=\\\\S+, validation roc_auc_score <score>=(\\\\S+)'},\n",
       "    {'Name': 'train:precision',\n",
       "     'Regex': '#quality_metric: host=\\\\S+, train precision <score>=(\\\\S+)'},\n",
       "    {'Name': 'train:objective_loss:final',\n",
       "     'Regex': '#quality_metric: host=\\\\S+, train \\\\S+_objective <loss>=(\\\\S+)'},\n",
       "    {'Name': 'validation:recall',\n",
       "     'Regex': '#quality_metric: host=\\\\S+, validation recall <score>=(\\\\S+)'},\n",
       "    {'Name': 'test:multiclass_accuracy',\n",
       "     'Regex': '#quality_metric: host=\\\\S+, test multiclass_accuracy <score>=(\\\\S+)'},\n",
       "    {'Name': 'validation:precision',\n",
       "     'Regex': '#quality_metric: host=\\\\S+, validation precision <score>=(\\\\S+)'},\n",
       "    {'Name': 'validation:multiclass_accuracy',\n",
       "     'Regex': '#quality_metric: host=\\\\S+, validation multiclass_accuracy <score>=(\\\\S+)'},\n",
       "    {'Name': 'train:binary_f_beta',\n",
       "     'Regex': '#quality_metric: host=\\\\S+, train binary_f_\\\\S+ <score>=(\\\\S+)'},\n",
       "    {'Name': 'test:recall',\n",
       "     'Regex': '#quality_metric: host=\\\\S+, test recall <score>=(\\\\S+)'},\n",
       "    {'Name': 'test:macro_precision',\n",
       "     'Regex': '#quality_metric: host=\\\\S+, test macro_precision <score>=(\\\\S+)'},\n",
       "    {'Name': 'test:macro_f_beta',\n",
       "     'Regex': '#quality_metric: host=\\\\S+, test macro_f_\\\\S+ <score>=(\\\\S+)'},\n",
       "    {'Name': 'test:objective_loss',\n",
       "     'Regex': '#quality_metric: host=\\\\S+, test \\\\S+_objective <loss>=(\\\\S+)'},\n",
       "    {'Name': 'test:precision',\n",
       "     'Regex': '#quality_metric: host=\\\\S+, test precision <score>=(\\\\S+)'},\n",
       "    {'Name': 'validation:multiclass_top_k_accuracy',\n",
       "     'Regex': '#quality_metric: host=\\\\S+, validation multiclass_top_k_accuracy_\\\\S+ <score>=(\\\\S+)'},\n",
       "    {'Name': 'train:binary_classification_accuracy',\n",
       "     'Regex': '#quality_metric: host=\\\\S+, train binary_classification_accuracy <score>=(\\\\S+)'},\n",
       "    {'Name': 'validation:mse',\n",
       "     'Regex': '#quality_metric: host=\\\\S+, validation mse <loss>=(\\\\S+)'},\n",
       "    {'Name': 'test:multiclass_top_k_accuracy',\n",
       "     'Regex': '#quality_metric: host=\\\\S+, test multiclass_top_k_accuracy_\\\\S+ <score>=(\\\\S+)'},\n",
       "    {'Name': 'validation:binary_classification_accuracy',\n",
       "     'Regex': '#quality_metric: host=\\\\S+, validation binary_classification_accuracy <score>=(\\\\S+)'},\n",
       "    {'Name': 'train:absolute_loss',\n",
       "     'Regex': '#quality_metric: host=\\\\S+, train absolute_loss <loss>=(\\\\S+)'},\n",
       "    {'Name': 'validation:macro_recall',\n",
       "     'Regex': '#quality_metric: host=\\\\S+, validation macro_recall <score>=(\\\\S+)'},\n",
       "    {'Name': 'train:throughput',\n",
       "     'Regex': '#throughput_metric: host=\\\\S+, train throughput=(\\\\S+) records/second'},\n",
       "    {'Name': 'test:binary_classification_accuracy',\n",
       "     'Regex': '#quality_metric: host=\\\\S+, test binary_classification_accuracy <score>=(\\\\S+)'},\n",
       "    {'Name': 'validation:absolute_loss',\n",
       "     'Regex': '#quality_metric: host=\\\\S+, validation absolute_loss <loss>=(\\\\S+)'},\n",
       "    {'Name': 'validation:macro_f_beta',\n",
       "     'Regex': '#quality_metric: host=\\\\S+, validation macro_f_\\\\S+ <score>=(\\\\S+)'},\n",
       "    {'Name': 'test:roc_auc_score',\n",
       "     'Regex': '#quality_metric: host=\\\\S+, test roc_auc_score <score>=(\\\\S+)'},\n",
       "    {'Name': 'ObjectiveMetric',\n",
       "     'Regex': '#quality_metric: host=\\\\S+, validation binary_f_\\\\S+ <score>=(\\\\S+)'}]},\n",
       "  'RoleArn': 'arn:aws:iam::785913330910:role/service-role/AmazonSageMaker-ExecutionRole-20200718T190440',\n",
       "  'InputDataConfig': [{'ChannelName': 'train',\n",
       "    'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "      'S3Uri': 's3://sagemaker-us-west-2-785913330910/mle-capstone/train.csv',\n",
       "      'S3DataDistributionType': 'FullyReplicated'}},\n",
       "    'ContentType': 'text/csv'},\n",
       "   {'ChannelName': 'validation',\n",
       "    'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "      'S3Uri': 's3://sagemaker-us-west-2-785913330910/mle-capstone/validation.csv',\n",
       "      'S3DataDistributionType': 'FullyReplicated'}},\n",
       "    'ContentType': 'text/csv'}],\n",
       "  'OutputDataConfig': {'S3OutputPath': 's3://sagemaker-us-west-2-785913330910/mle-capstone/output'},\n",
       "  'ResourceConfig': {'InstanceType': 'ml.m4.xlarge',\n",
       "   'InstanceCount': 1,\n",
       "   'VolumeSizeInGB': 30},\n",
       "  'StoppingCondition': {'MaxRuntimeInSeconds': 86400},\n",
       "  'EnableNetworkIsolation': False,\n",
       "  'EnableInterContainerTrafficEncryption': False,\n",
       "  'EnableManagedSpotTraining': False},\n",
       " 'HyperParameterTuningJobStatus': 'Completed',\n",
       " 'CreationTime': datetime.datetime(2021, 3, 5, 5, 56, 20, 731000, tzinfo=tzlocal()),\n",
       " 'HyperParameterTuningEndTime': datetime.datetime(2021, 3, 5, 6, 28, 43, 518000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2021, 3, 5, 6, 28, 43, 518000, tzinfo=tzlocal()),\n",
       " 'TrainingJobStatusCounters': {'Completed': 20,\n",
       "  'InProgress': 0,\n",
       "  'RetryableError': 0,\n",
       "  'NonRetryableError': 0,\n",
       "  'Stopped': 0},\n",
       " 'ObjectiveStatusCounters': {'Succeeded': 20, 'Pending': 0, 'Failed': 0},\n",
       " 'BestTrainingJob': {'TrainingJobName': 'linear-learner-210305-0556-020-3d7538db',\n",
       "  'TrainingJobArn': 'arn:aws:sagemaker:us-west-2:785913330910:training-job/linear-learner-210305-0556-020-3d7538db',\n",
       "  'CreationTime': datetime.datetime(2021, 3, 5, 6, 23, 40, tzinfo=tzlocal()),\n",
       "  'TrainingStartTime': datetime.datetime(2021, 3, 5, 6, 25, 55, tzinfo=tzlocal()),\n",
       "  'TrainingEndTime': datetime.datetime(2021, 3, 5, 6, 27, 17, tzinfo=tzlocal()),\n",
       "  'TrainingJobStatus': 'Completed',\n",
       "  'TunedHyperParameters': {'l1': '0.06803989651132132',\n",
       "   'learning_rate': '0.1935662317782227',\n",
       "   'mini_batch_size': '272',\n",
       "   'positive_example_weight_mult': '2.195255799352273',\n",
       "   'use_bias': 'False',\n",
       "   'wd': '0.008273718580338141'},\n",
       "  'FinalHyperParameterTuningJobObjectiveMetric': {'MetricName': 'validation:binary_f_beta',\n",
       "   'Value': 0.8078495264053345},\n",
       "  'ObjectiveStatus': 'Succeeded'},\n",
       " 'ResponseMetadata': {'RequestId': 'ae44c07e-3a77-460c-aeb3-f736d7d2594c',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'ae44c07e-3a77-460c-aeb3-f736d7d2594c',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '7928',\n",
       "   'date': 'Fri, 05 Mar 2021 06:29:48 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describe the tuning job\n",
    "linear_hyperparameter_tuner.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-03-05 06:27:17 Starting - Preparing the instances for training\n",
      "2021-03-05 06:27:17 Downloading - Downloading input data\n",
      "2021-03-05 06:27:17 Training - Training image download completed. Training in progress.\n",
      "2021-03-05 06:27:17 Uploading - Uploading generated training model\n",
      "2021-03-05 06:27:17 Completed - Training job completed\n"
     ]
    }
   ],
   "source": [
    "# create an estimator object from the best training job\n",
    "linear_attached = sagemaker.estimator.Estimator.attach(linear_hyperparameter_tuner.best_training_job())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up hosting for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "linear_predictor = linear_attached.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.c4.xlarge\",\n",
    "    serializer=CSVSerializer(),\n",
    "    deserializer=JSONDeserializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions on the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the test data from s3\n",
    "X_test = pd.read_csv(test_location, header=None)\n",
    "Y_test = pd.read_csv(Y_test_location, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions on the test data\n",
    "result = linear_predictor.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of predicted labels\n",
    "y_pred_class = [x['predicted_label'] for x in result['predictions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of predicted probabilities for each observation\n",
    "y_pred_prob = [x['score'] for x in result['predictions']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 4549\n",
      "False Positives: 1990\n",
      "False Negatives: 637\n",
      "True Positives: 5484\n",
      "Sensitivty: 0.8959320372488155\n",
      "Specificty: 0.6956721211194372\n",
      "Accuracy: 0.7924960505529226\n",
      "0.7924960505529226\n",
      "0.8067671938212577\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Confusion Matrix and Accuracy\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test, y_pred_class).ravel()\n",
    "# accuracy = (tp + tn) / (tp + fp + fn + tn)\n",
    "print(f\"True Negatives: {tn}\")\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Positives: {tp}\")\n",
    "print(f\"Sensitivty: {tp/(tp+fn)}\")\n",
    "print(f\"Specificty: {tn/(tn+fp)}\")\n",
    "print(f\"Accuracy: {(tp+tn)/((tp+ tn+fp+fn))}\")\n",
    "print(accuracy_score(Y_test, y_pred_class))\n",
    "print(f1_score(Y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the f1 score of our initial Linear Learner model was 80.8%, so this model performs about the same with an f1 score of 80.7%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Accuracy and F1 with Different Predicted Probability Thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default predicted probability threshold used to classify observations into the positve (conversions) and negative class (non-conversions) is 0.5.\n",
    "\n",
    "It's often useful to see how using different thresholds can impact the evaluation metric of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loooping through a wide range of thresholds and classifying observations\n",
    "f1_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "thresholds = np.linspace(start = 0.05, stop = 0.9, num = 40)\n",
    "\n",
    "for i in thresholds:\n",
    "    temp_pred = [1 if x >= i else 0 for x in y_pred_prob]\n",
    "    \n",
    "    temp_f1 = f1_score(Y_test, temp_pred)\n",
    "    temp_accuracy = accuracy_score(Y_test, temp_pred)\n",
    "    \n",
    "    f1_list.append(temp_f1)\n",
    "    accuracy_list.append(temp_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.731521</td>\n",
       "      <td>0.645103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.071795</td>\n",
       "      <td>0.743562</td>\n",
       "      <td>0.666509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.093590</td>\n",
       "      <td>0.750306</td>\n",
       "      <td>0.678199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.756707</td>\n",
       "      <td>0.689100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.137179</td>\n",
       "      <td>0.760703</td>\n",
       "      <td>0.695814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.158974</td>\n",
       "      <td>0.766610</td>\n",
       "      <td>0.705608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.180769</td>\n",
       "      <td>0.772360</td>\n",
       "      <td>0.715324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.202564</td>\n",
       "      <td>0.774320</td>\n",
       "      <td>0.718720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.224359</td>\n",
       "      <td>0.779380</td>\n",
       "      <td>0.726856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.246154</td>\n",
       "      <td>0.786315</td>\n",
       "      <td>0.739021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.267949</td>\n",
       "      <td>0.787694</td>\n",
       "      <td>0.741627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.289744</td>\n",
       "      <td>0.789693</td>\n",
       "      <td>0.744708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.311538</td>\n",
       "      <td>0.792601</td>\n",
       "      <td>0.749368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.794787</td>\n",
       "      <td>0.754976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.355128</td>\n",
       "      <td>0.795313</td>\n",
       "      <td>0.755766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.376923</td>\n",
       "      <td>0.796368</td>\n",
       "      <td>0.759084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.398718</td>\n",
       "      <td>0.797245</td>\n",
       "      <td>0.760506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.420513</td>\n",
       "      <td>0.798765</td>\n",
       "      <td>0.763112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.442308</td>\n",
       "      <td>0.800541</td>\n",
       "      <td>0.766825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.464103</td>\n",
       "      <td>0.801273</td>\n",
       "      <td>0.768167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.485897</td>\n",
       "      <td>0.801994</td>\n",
       "      <td>0.771011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.802993</td>\n",
       "      <td>0.773302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.529487</td>\n",
       "      <td>0.804733</td>\n",
       "      <td>0.777093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.551282</td>\n",
       "      <td>0.805858</td>\n",
       "      <td>0.780095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.573077</td>\n",
       "      <td>0.806717</td>\n",
       "      <td>0.782701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.594872</td>\n",
       "      <td>0.808066</td>\n",
       "      <td>0.786493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.807378</td>\n",
       "      <td>0.787994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.638462</td>\n",
       "      <td>0.808523</td>\n",
       "      <td>0.792022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.660256</td>\n",
       "      <td>0.806873</td>\n",
       "      <td>0.793128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.682051</td>\n",
       "      <td>0.805061</td>\n",
       "      <td>0.794313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.703846</td>\n",
       "      <td>0.801437</td>\n",
       "      <td>0.794787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.725641</td>\n",
       "      <td>0.796687</td>\n",
       "      <td>0.794471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.747436</td>\n",
       "      <td>0.789717</td>\n",
       "      <td>0.791943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.776891</td>\n",
       "      <td>0.785861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.791026</td>\n",
       "      <td>0.758109</td>\n",
       "      <td>0.776145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.812821</td>\n",
       "      <td>0.737579</td>\n",
       "      <td>0.765956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.834615</td>\n",
       "      <td>0.702577</td>\n",
       "      <td>0.747472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.856410</td>\n",
       "      <td>0.658729</td>\n",
       "      <td>0.726066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.878205</td>\n",
       "      <td>0.604403</td>\n",
       "      <td>0.701896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.522451</td>\n",
       "      <td>0.668167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    threshold        f1  accuracy\n",
       "0    0.050000  0.731521  0.645103\n",
       "1    0.071795  0.743562  0.666509\n",
       "2    0.093590  0.750306  0.678199\n",
       "3    0.115385  0.756707  0.689100\n",
       "4    0.137179  0.760703  0.695814\n",
       "5    0.158974  0.766610  0.705608\n",
       "6    0.180769  0.772360  0.715324\n",
       "7    0.202564  0.774320  0.718720\n",
       "8    0.224359  0.779380  0.726856\n",
       "9    0.246154  0.786315  0.739021\n",
       "10   0.267949  0.787694  0.741627\n",
       "11   0.289744  0.789693  0.744708\n",
       "12   0.311538  0.792601  0.749368\n",
       "13   0.333333  0.794787  0.754976\n",
       "14   0.355128  0.795313  0.755766\n",
       "15   0.376923  0.796368  0.759084\n",
       "16   0.398718  0.797245  0.760506\n",
       "17   0.420513  0.798765  0.763112\n",
       "18   0.442308  0.800541  0.766825\n",
       "19   0.464103  0.801273  0.768167\n",
       "20   0.485897  0.801994  0.771011\n",
       "21   0.507692  0.802993  0.773302\n",
       "22   0.529487  0.804733  0.777093\n",
       "23   0.551282  0.805858  0.780095\n",
       "24   0.573077  0.806717  0.782701\n",
       "25   0.594872  0.808066  0.786493\n",
       "26   0.616667  0.807378  0.787994\n",
       "27   0.638462  0.808523  0.792022\n",
       "28   0.660256  0.806873  0.793128\n",
       "29   0.682051  0.805061  0.794313\n",
       "30   0.703846  0.801437  0.794787\n",
       "31   0.725641  0.796687  0.794471\n",
       "32   0.747436  0.789717  0.791943\n",
       "33   0.769231  0.776891  0.785861\n",
       "34   0.791026  0.758109  0.776145\n",
       "35   0.812821  0.737579  0.765956\n",
       "36   0.834615  0.702577  0.747472\n",
       "37   0.856410  0.658729  0.726066\n",
       "38   0.878205  0.604403  0.701896\n",
       "39   0.900000  0.522451  0.668167"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# storing results in a dataframe\n",
    "df_f1_accuracy = pd.DataFrame({'threshold': thresholds\n",
    "                          , 'f1': f1_list\n",
    "                          , 'accuracy': accuracy_list})\n",
    "df_f1_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27    0.638462\n",
       "Name: threshold, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicted probabilty that maximizes the f1 score\n",
    "max_f1 = df_f1_accuracy['f1'].max()\n",
    "\n",
    "df_f1_accuracy[df_f1_accuracy['f1'] == max_f1]['threshold']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Predicted Probabilites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also useful to plot the distribution of the predicted probabilities because it provides more insight into how the model is classifying observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_pred_prob, bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Predicted Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing results in a dataframe\n",
    "df_pred_prob = pd.DataFrame({'y_pred_prob': y_pred_prob})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df to csv \n",
    "df_pred_prob.to_csv(os.path.join(data_dir, 'y_pred_prob_model_2.csv'), header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save csv to s3\n",
    "y_pred_prob_model_1_location = session.upload_data(os.path.join(data_dir, 'y_pred_prob_model_2.csv'), bucket = bucket, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted linear-learner-2021-03-05-06-30-03-913 successfully!\n"
     ]
    }
   ],
   "source": [
    "sagemaker.Session().delete_endpoint(linear_predictor.endpoint_name)\n",
    "print(f\"deleted {linear_predictor.endpoint_name} successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
