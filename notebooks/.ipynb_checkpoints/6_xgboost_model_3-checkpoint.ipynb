{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import json\n",
    "import io\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn.model_selection\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker.predictor import csv_serializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an object that represents the SageMaker session that we are currently operating in. This\n",
    "# object contains some useful information that we will need to access later such as our region.\n",
    "session = sagemaker.Session()\n",
    "\n",
    "# This is an object that represents the IAM role that we are currently assigned. When we construct\n",
    "# and launch the training job later we will need to tell it what IAM role it should have. Since our\n",
    "# use case is relatively simple we will simply assign the training job the role we currently have.\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Input Data Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is our local data directory. We need to make sure that it exists.\n",
    "data_dir = '../input'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "    \n",
    "# s3 bucket and prefix (folder in s3)\n",
    "bucket = session.default_bucket()\n",
    "prefix = 'mle-capstone'\n",
    "\n",
    "# location of datasets in s3\n",
    "train_location = f's3://{bucket}/{prefix}/train.csv'\n",
    "val_location = f's3://{bucket}/{prefix}/validation.csv'\n",
    "test_location = f's3://{bucket}/{prefix}/test.csv'\n",
    "Y_test_location = f's3://{bucket}/{prefix}/Y_test.csv'\n",
    "test_unprocessed_location = f's3://{bucket}/{prefix}/test_unprocessed.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and construct the XGBoost model\n",
    "\n",
    "Now that we have the training and validation data uploaded to S3, we can construct a training job for our XGBoost model and build the model itself.\n",
    "\n",
    "### Set up the training job\n",
    "\n",
    "First, we will set up and execute a training job for our model. To do this we need to specify some information that SageMaker will use to set up and properly execute the computation. For additional documentation on constructing a training job, see the [CreateTrainingJob API](https://docs.aws.amazon.com/sagemaker/latest/dg/API_CreateTrainingJob.html) reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will need to know the name of the container that we want to use for training. SageMaker provides\n",
    "# a nice utility method to construct this for us.\n",
    "container = '246618743249.dkr.ecr.us-west-2.amazonaws.com'+'/sagemaker-xgboost:1.0-1-cpu-py3'\n",
    "\n",
    "# We now specify the parameters we wish to use for our training job\n",
    "training_params = {}\n",
    "\n",
    "# We need to specify the permissions that this training job will have. For our purposes we can use\n",
    "# the same permissions that our current SageMaker session has.\n",
    "training_params['RoleArn'] = role\n",
    "\n",
    "# Here we describe the algorithm we wish to use. The most important part is the container which\n",
    "# contains the training code.\n",
    "training_params['AlgorithmSpecification'] = {\n",
    "    \"TrainingImage\": container,\n",
    "    \"TrainingInputMode\": \"File\"\n",
    "}\n",
    "\n",
    "# We also need to say where we would like the resulting model artifacts stored.\n",
    "training_params['OutputDataConfig'] = {\n",
    "    \"S3OutputPath\": \"s3://\" + session.default_bucket() + \"/\" + prefix + \"/output\"\n",
    "}\n",
    "\n",
    "# We also need to set some parameters for the training job itself. Namely we need to describe what sort of\n",
    "# compute instance we wish to use along with a stopping condition to handle the case that there is\n",
    "# some sort of error and the training script doesn't terminate.\n",
    "training_params['ResourceConfig'] = {\n",
    "    \"InstanceCount\": 1,\n",
    "    \"InstanceType\": \"ml.m4.xlarge\",\n",
    "    \"VolumeSizeInGB\": 5\n",
    "}\n",
    "    \n",
    "training_params['StoppingCondition'] = {\n",
    "    \"MaxRuntimeInSeconds\": 86400\n",
    "}\n",
    "\n",
    "# Next we set the algorithm specific hyperparameters. You may wish to change these to see what effect\n",
    "# there is on the resulting model.\n",
    "training_params['HyperParameters'] = {\n",
    "    \"max_depth\": \"5\",\n",
    "    \"eta\": \"0.2\",\n",
    "    \"gamma\": \"4\",\n",
    "    \"min_child_weight\": \"6\",\n",
    "    \"subsample\": \"0.8\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"early_stopping_rounds\": \"10\",\n",
    "    \"num_round\": \"200\"\n",
    "}\n",
    "\n",
    "# Now we need to tell SageMaker where the data should be retrieved from.\n",
    "training_params['InputDataConfig'] = [\n",
    "    {\n",
    "        \"ChannelName\": \"train\",\n",
    "        \"DataSource\": {\n",
    "            \"S3DataSource\": {\n",
    "                \"S3DataType\": \"S3Prefix\",\n",
    "                \"S3Uri\": train_location,\n",
    "                \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "            }\n",
    "        },\n",
    "        \"ContentType\": \"csv\",\n",
    "        \"CompressionType\": \"None\"\n",
    "    },\n",
    "    {\n",
    "        \"ChannelName\": \"validation\",\n",
    "        \"DataSource\": {\n",
    "            \"S3DataSource\": {\n",
    "                \"S3DataType\": \"S3Prefix\",\n",
    "                \"S3Uri\": val_location,\n",
    "                \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "            }\n",
    "        },\n",
    "        \"ContentType\": \"csv\",\n",
    "        \"CompressionType\": \"None\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[XGBoost Hyperparameter Documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost_hyperparameters.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the training job\n",
    "\n",
    "Now that we've built the dictionary object containing the training job parameters, we can ask SageMaker to execute the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to choose a training job name. This is useful for if we want to recall information about our\n",
    "# training job at a later date. Note that SageMaker requires a training job name and that the name needs to\n",
    "# be unique, which we accomplish by appending the current timestamp.\n",
    "training_job_name = \"starbucks-xgboost-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "training_params['TrainingJobName'] = training_job_name\n",
    "\n",
    "# And now we ask SageMaker to create (and execute) the training job\n",
    "training_job = session.sagemaker_client.create_training_job(**training_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-03 09:26:20 Starting - Starting the training job...\n",
      "2021-03-03 09:26:22 Starting - Launching requested ML instances......\n",
      "2021-03-03 09:27:32 Starting - Preparing the instances for training......\n",
      "2021-03-03 09:28:30 Downloading - Downloading input data...\n",
      "2021-03-03 09:28:52 Training - Downloading the training image..\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[09:29:27] 25444x14 matrix with 356216 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[09:29:27] 12533x14 matrix with 175462 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 25444 rows\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 12533 rows\u001b[0m\n",
      "\u001b[34m[09:29:27] WARNING: /workspace/src/learner.cc:328: \u001b[0m\n",
      "\u001b[34mParameters: { early_stopping_rounds, num_round } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.20893#011validation-error:0.21224\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.20115#011validation-error:0.20314\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.19812#011validation-error:0.20019\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.19808#011validation-error:0.20243\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.19478#011validation-error:0.19676\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.19431#011validation-error:0.19812\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.19403#011validation-error:0.19804\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.19164#011validation-error:0.19668\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.19234#011validation-error:0.19756\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.19140#011validation-error:0.19788\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.19148#011validation-error:0.19828\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.19077#011validation-error:0.19915\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.19101#011validation-error:0.19892\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.19077#011validation-error:0.19724\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.19030#011validation-error:0.19684\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.18940#011validation-error:0.19668\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.18971#011validation-error:0.19660\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.18857#011validation-error:0.19620\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.18853#011validation-error:0.19604\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.18845#011validation-error:0.19580\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.18845#011validation-error:0.19612\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.18775#011validation-error:0.19644\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.18743#011validation-error:0.19572\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.18688#011validation-error:0.19532\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.18700#011validation-error:0.19517\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.18735#011validation-error:0.19525\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.18704#011validation-error:0.19477\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.18731#011validation-error:0.19461\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.18735#011validation-error:0.19469\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.18724#011validation-error:0.19461\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.18668#011validation-error:0.19477\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.18645#011validation-error:0.19461\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.18637#011validation-error:0.19445\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.18617#011validation-error:0.19453\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.18594#011validation-error:0.19501\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.18566#011validation-error:0.19397\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.18598#011validation-error:0.19572\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.18562#011validation-error:0.19509\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.18554#011validation-error:0.19492\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.18558#011validation-error:0.19469\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.18523#011validation-error:0.19492\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.18547#011validation-error:0.19501\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.18543#011validation-error:0.19532\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.18519#011validation-error:0.19509\u001b[0m\n",
      "\u001b[34m[44]#011train-error:0.18531#011validation-error:0.19517\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.18468#011validation-error:0.19501\u001b[0m\n",
      "\n",
      "2021-03-03 09:29:37 Uploading - Uploading generated training model\n",
      "2021-03-03 09:29:37 Completed - Training job completed\n",
      "Training seconds: 67\n",
      "Billable seconds: 67\n"
     ]
    }
   ],
   "source": [
    "# monitor the job progress\n",
    "session.logs_for_job(training_job_name, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model\n",
    "\n",
    "Now that the training job has completed, we have some model artifacts which we can use to build a model. Note that here we mean SageMaker's definition of a model, which is a collection of information about a specific algorithm along with the artifacts which result from a training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We begin by asking SageMaker to describe for us the results of the training job. The data structure\n",
    "# returned contains a lot more information than we currently need, try checking it out yourself in\n",
    "# more detail.\n",
    "training_job_info = session.sagemaker_client.describe_training_job(TrainingJobName=training_job_name)\n",
    "\n",
    "model_artifacts = training_job_info['ModelArtifacts']['S3ModelArtifacts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just like when we created a training job, the model name must be unique\n",
    "model_name = training_job_name + \"-model\"\n",
    "\n",
    "# We also need to tell SageMaker which container should be used for inference and where it should\n",
    "# retrieve the model artifacts from. In our case, the xgboost container that we used for training\n",
    "# can also be used for inference.\n",
    "primary_container = {\n",
    "    \"Image\": container,\n",
    "    \"ModelDataUrl\": model_artifacts\n",
    "}\n",
    "\n",
    "# And lastly we construct the SageMaker model\n",
    "model_info = session.sagemaker_client.create_model(\n",
    "                                ModelName = model_name,\n",
    "                                ExecutionRoleArn = role,\n",
    "                                PrimaryContainer = primary_container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model\n",
    "\n",
    "Now that we have fit our model to the training data, using the validation data to avoid overfitting, we can test our model. To do this we will make use of SageMaker's Batch Transform functionality. In other words, we need to set up and execute a batch transform job, similar to the way that we constructed the training job earlier.\n",
    "\n",
    "### Set up the batch transform job\n",
    "\n",
    "Just like when we were training our model, we first need to provide some information in the form of a data structure that describes the batch transform job which we wish to execute.\n",
    "\n",
    "We will only be using some of the options available here but to see some of the additional options please see the SageMaker documentation for [creating a batch transform job](https://docs.aws.amazon.com/sagemaker/latest/dg/API_CreateTransformJob.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just like in each of the previous steps, we need to make sure to name our job and the name should be unique.\n",
    "transform_job_name = 'mle-capstone-xgboost-batch-transform-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "# Now we construct the data structure which will describe the batch transform job.\n",
    "transform_request = \\\n",
    "{\n",
    "    \"TransformJobName\": transform_job_name,\n",
    "    \n",
    "    # This is the name of the model that we created earlier.\n",
    "    \"ModelName\": model_name,\n",
    "    \n",
    "    # This describes how many compute instances should be used at once. If you happen to be doing a very large\n",
    "    # batch transform job it may be worth running multiple compute instances at once.\n",
    "    \"MaxConcurrentTransforms\": 1,\n",
    "    \n",
    "    # This says how big each individual request sent to the model should be, at most. One of the things that\n",
    "    # SageMaker does in the background is to split our data up into chunks so that each chunks stays under\n",
    "    # this size limit.\n",
    "    \"MaxPayloadInMB\": 6,\n",
    "    \n",
    "    # Sometimes we may want to send only a single sample to our endpoint at a time, however in this case each of\n",
    "    # the chunks that we send should contain multiple samples of our input data.\n",
    "    \"BatchStrategy\": \"MultiRecord\",\n",
    "    \n",
    "    # This next object describes where the output data should be stored. Some of the more advanced options which\n",
    "    # we don't cover here also describe how SageMaker should collect output from various batches.\n",
    "    \"TransformOutput\": {\n",
    "        \"S3OutputPath\": \"s3://{}/{}/batch-transform/\".format(session.default_bucket(),prefix)\n",
    "    },\n",
    "    \n",
    "    # Here we describe our input data. Of course, we need to tell SageMaker where on S3 our input data is stored, in\n",
    "    # addition we need to detail the characteristics of our input data. In particular, since SageMaker may need to\n",
    "    # split our data up into chunks, it needs to know how the individual samples in our data file appear. In our\n",
    "    # case each line is its own sample and so we set the split type to 'line'. We also need to tell SageMaker what\n",
    "    # type of data is being sent, in this case csv, so that it can properly serialize the data.\n",
    "    \"TransformInput\": {\n",
    "        \"ContentType\": \"text/csv\",\n",
    "        \"SplitType\": \"Line\",\n",
    "        \"DataSource\": {\n",
    "            \"S3DataSource\": {\n",
    "                \"S3DataType\": \"S3Prefix\",\n",
    "                \"S3Uri\": test_location,\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # And lastly we tell SageMaker what sort of compute instance we would like it to use.\n",
    "    \"TransformResources\": {\n",
    "            \"InstanceType\": \"ml.m4.xlarge\",\n",
    "            \"InstanceCount\": 1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the batch transform job\n",
    "\n",
    "Now that we have created the request data structure, it is time to ask SageMaker to set up and run our batch transform job. Just like in the previous steps, SageMaker performs these tasks in the background so that if we want to wait for the transform job to terminate (and ensure the job is progressing) we can ask SageMaker to wait of the transform job to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_response = session.sagemaker_client.create_transform_job(**transform_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................................!\n"
     ]
    }
   ],
   "source": [
    "transform_desc = session.wait_for_transform_job(transform_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the results\n",
    "\n",
    "Now that the transform job has completed, the results are stored on S3 as we requested. Since we'd like to do a bit of analysis in the notebook we can use some notebook magic to copy the resulting output from S3 and save it locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-west-2-785913330910/mle-capstone/batch-bransform/'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_output = \"s3://{}/{}/batch-bransform/\".format(session.default_bucket(),prefix)\n",
    "transform_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive $transform_output $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-west-2-785913330910\n",
      "mle-capstone/batch-transform/\n",
      "ParseResult(scheme='s3', netloc='sagemaker-us-west-2-785913330910', path='/mle-capstone/batch-transform/', params='', query='', fragment='')\n"
     ]
    }
   ],
   "source": [
    "# parse the s3uri\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "s3uri = transform_request['TransformOutput']['S3OutputPath']\n",
    "\n",
    "parsed_url = urlparse(s3uri)\n",
    "batch_file = 'test.csv'\n",
    "\n",
    "output_bucket_name = parsed_url.netloc\n",
    "output_prefix = parsed_url.path[1:]\n",
    "print(output_bucket_name)\n",
    "print(output_prefix)\n",
    "print(parsed_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the test data object from s3\n",
    "obj = s3.Object(bucket_name = output_bucket_name, key = 'mle-capstone/batch-transform/test.csv.out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the result\n",
    "result = obj.get()[\"Body\"].read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the predicted probabilities\n",
    "Y_pred_prob = pd.read_csv(io.StringIO(result), sep=\",\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12660, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.830645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.911853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.942162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.128885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.567132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.945552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.926978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  0.830645\n",
       "1  0.001296\n",
       "2  0.911853\n",
       "3  0.942162\n",
       "4  0.001310\n",
       "5  0.128885\n",
       "6  0.001350\n",
       "7  0.567132\n",
       "8  0.945552\n",
       "9  0.926978"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_prob.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  0\n",
       "2  1\n",
       "3  1\n",
       "4  0\n",
       "5  1\n",
       "6  0\n",
       "7  1\n",
       "8  1\n",
       "9  1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the Y_test data from s3\n",
    "Y_test = pd.read_csv(Y_test_location, header=None)\n",
    "Y_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Next we need to use our predicted probabilities to generate classifications\n",
    "# set positive class threshold \n",
    "threshold = 0.5\n",
    "y_pred_pos = Y_pred_prob[0]\n",
    "y_pred_class = y_pred_pos > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 4868\n",
      "False Positives: 1671\n",
      "False Negatives: 811\n",
      "True Positives: 5310\n",
      "Sensitivty: 0.8675053095899363\n",
      "Specificty: 0.7444563388897385\n",
      "Accuracy: 0.8039494470774091\n",
      "0.8039494470774091\n",
      "0.8105632727827813\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix and Accuracy\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test, y_pred_class).ravel()\n",
    "# accuracy = (tp + tn) / (tp + fp + fn + tn)\n",
    "print(f\"True Negatives: {tn}\")\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Positives: {tp}\")\n",
    "print(f\"Sensitivty: {tp/(tp+fn)}\")\n",
    "print(f\"Specificty: {tn/(tn+fp)}\")\n",
    "print(f\"Accuracy: {(tp+tn)/((tp+ tn+fp+fn))}\")\n",
    "print(accuracy_score(Y_test, y_pred_class))\n",
    "print(f1_score(Y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The XGBoost model results in a slight improvement in the f1 score of 81.1% (vs 80.7% in our Linear Learner benchmark model.\n",
    "\n",
    "Additionally, the XGboost model seems to do a better job of classifying the non converters than the Linear Learner model. The Specificity, or the proportion of the negative class that was predicted correctly, is the highest among the 3 models at 74% (vs 68% for the Linear Learner benchmark model). Though the proportion of the positive class (Sensitivity) is slightly lower at 87% compared to 91% in benchamrk model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Accuracy and F1 with Different Predicted Probability Thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default predicted probability threshold used to classify observations into the positve (conversions) and negative class (non-conversions) is 0.5.\n",
    "\n",
    "It's often useful to see how using different thresholds can impact the evaluation metric of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loooping through a wide range of thresholds and classifying observations\n",
    "f1_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "thresholds = np.linspace(start = 0.05, stop = 0.9, num = 40)\n",
    "\n",
    "for i in thresholds:\n",
    "    temp_pred = [1 if x >= i else 0 for x in y_pred_pos]\n",
    "    \n",
    "    temp_f1 = f1_score(Y_test, temp_pred)\n",
    "    temp_accuracy = accuracy_score(Y_test, temp_pred)\n",
    "    \n",
    "    f1_list.append(temp_f1)\n",
    "    accuracy_list.append(temp_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.777198</td>\n",
       "      <td>0.723381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.071795</td>\n",
       "      <td>0.778678</td>\n",
       "      <td>0.725829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.093590</td>\n",
       "      <td>0.782263</td>\n",
       "      <td>0.731596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.785268</td>\n",
       "      <td>0.736572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.137179</td>\n",
       "      <td>0.791580</td>\n",
       "      <td>0.746603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.158974</td>\n",
       "      <td>0.792758</td>\n",
       "      <td>0.748657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.180769</td>\n",
       "      <td>0.797244</td>\n",
       "      <td>0.755924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.202564</td>\n",
       "      <td>0.800318</td>\n",
       "      <td>0.761769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.224359</td>\n",
       "      <td>0.803640</td>\n",
       "      <td>0.768167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.246154</td>\n",
       "      <td>0.804873</td>\n",
       "      <td>0.771011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.267949</td>\n",
       "      <td>0.807538</td>\n",
       "      <td>0.776540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.289744</td>\n",
       "      <td>0.809752</td>\n",
       "      <td>0.780569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.311538</td>\n",
       "      <td>0.811227</td>\n",
       "      <td>0.784834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.812868</td>\n",
       "      <td>0.789100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.355128</td>\n",
       "      <td>0.813813</td>\n",
       "      <td>0.791311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.376923</td>\n",
       "      <td>0.814693</td>\n",
       "      <td>0.794787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.398718</td>\n",
       "      <td>0.815926</td>\n",
       "      <td>0.798420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.420513</td>\n",
       "      <td>0.813740</td>\n",
       "      <td>0.798262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.442308</td>\n",
       "      <td>0.812565</td>\n",
       "      <td>0.799210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.464103</td>\n",
       "      <td>0.812271</td>\n",
       "      <td>0.801343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.485897</td>\n",
       "      <td>0.810663</td>\n",
       "      <td>0.802528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.809666</td>\n",
       "      <td>0.804028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.529487</td>\n",
       "      <td>0.805709</td>\n",
       "      <td>0.803239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.551282</td>\n",
       "      <td>0.802261</td>\n",
       "      <td>0.803791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.573077</td>\n",
       "      <td>0.797334</td>\n",
       "      <td>0.803081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.594872</td>\n",
       "      <td>0.788894</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.774927</td>\n",
       "      <td>0.792101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.638462</td>\n",
       "      <td>0.764629</td>\n",
       "      <td>0.787441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.660256</td>\n",
       "      <td>0.751657</td>\n",
       "      <td>0.781043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.682051</td>\n",
       "      <td>0.734460</td>\n",
       "      <td>0.772907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.703846</td>\n",
       "      <td>0.716999</td>\n",
       "      <td>0.764613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.725641</td>\n",
       "      <td>0.697720</td>\n",
       "      <td>0.754976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.747436</td>\n",
       "      <td>0.679745</td>\n",
       "      <td>0.745972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.651287</td>\n",
       "      <td>0.732543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.791026</td>\n",
       "      <td>0.621498</td>\n",
       "      <td>0.719352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.812821</td>\n",
       "      <td>0.590904</td>\n",
       "      <td>0.706556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.834615</td>\n",
       "      <td>0.544307</td>\n",
       "      <td>0.686414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.856410</td>\n",
       "      <td>0.501072</td>\n",
       "      <td>0.669194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.878205</td>\n",
       "      <td>0.461292</td>\n",
       "      <td>0.654265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.406102</td>\n",
       "      <td>0.634044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    threshold        f1  accuracy\n",
       "0    0.050000  0.777198  0.723381\n",
       "1    0.071795  0.778678  0.725829\n",
       "2    0.093590  0.782263  0.731596\n",
       "3    0.115385  0.785268  0.736572\n",
       "4    0.137179  0.791580  0.746603\n",
       "5    0.158974  0.792758  0.748657\n",
       "6    0.180769  0.797244  0.755924\n",
       "7    0.202564  0.800318  0.761769\n",
       "8    0.224359  0.803640  0.768167\n",
       "9    0.246154  0.804873  0.771011\n",
       "10   0.267949  0.807538  0.776540\n",
       "11   0.289744  0.809752  0.780569\n",
       "12   0.311538  0.811227  0.784834\n",
       "13   0.333333  0.812868  0.789100\n",
       "14   0.355128  0.813813  0.791311\n",
       "15   0.376923  0.814693  0.794787\n",
       "16   0.398718  0.815926  0.798420\n",
       "17   0.420513  0.813740  0.798262\n",
       "18   0.442308  0.812565  0.799210\n",
       "19   0.464103  0.812271  0.801343\n",
       "20   0.485897  0.810663  0.802528\n",
       "21   0.507692  0.809666  0.804028\n",
       "22   0.529487  0.805709  0.803239\n",
       "23   0.551282  0.802261  0.803791\n",
       "24   0.573077  0.797334  0.803081\n",
       "25   0.594872  0.788894  0.800000\n",
       "26   0.616667  0.774927  0.792101\n",
       "27   0.638462  0.764629  0.787441\n",
       "28   0.660256  0.751657  0.781043\n",
       "29   0.682051  0.734460  0.772907\n",
       "30   0.703846  0.716999  0.764613\n",
       "31   0.725641  0.697720  0.754976\n",
       "32   0.747436  0.679745  0.745972\n",
       "33   0.769231  0.651287  0.732543\n",
       "34   0.791026  0.621498  0.719352\n",
       "35   0.812821  0.590904  0.706556\n",
       "36   0.834615  0.544307  0.686414\n",
       "37   0.856410  0.501072  0.669194\n",
       "38   0.878205  0.461292  0.654265\n",
       "39   0.900000  0.406102  0.634044"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f1_accuracy = pd.DataFrame({'threshold': thresholds\n",
    "                          , 'f1': f1_list\n",
    "                          , 'accuracy': accuracy_list})\n",
    "df_f1_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16    0.398718\n",
      "Name: threshold, dtype: float64\n",
      "0.8159261396422388\n"
     ]
    }
   ],
   "source": [
    "# predicted probabilty that maximizes the f1 score\n",
    "max_f1 = df_f1_accuracy['f1'].max()\n",
    "\n",
    "print(df_f1_accuracy[df_f1_accuracy['f1'] == max_f1]['threshold'])\n",
    "print(max_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Predicted Probabilites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_pred_pos, bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Predicted Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll do is to save the predicted probabilities to s3 so that we can easily use them for potential post hoc analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing results in a dataframe\n",
    "df_pred_prob = pd.DataFrame({'y_pred_prob': y_pred_pos})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df to csv \n",
    "df_pred_prob.to_csv(os.path.join(data_dir, 'y_pred_prob_model_3.csv'), header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to s3\n",
    "y_pred_prob_model_3_location = session.upload_data(os.path.join(data_dir, 'y_pred_prob_model_3.csv'), bucket = bucket, key_prefix=prefix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
